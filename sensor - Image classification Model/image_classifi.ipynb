{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello AI\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello AI\")\n",
        "from keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "cam = cv2.VideoCapture(0)\n",
        "# Load the model\n",
        "model = load_model('keras_model.h5')\n",
        "\n",
        "def image_capture():\n",
        "   ret,frame = cam.read()\n",
        "   cv2.imwrite (\"test.png\",frame)\n",
        "\n",
        "def image_detector():\n",
        "    \n",
        "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "    # Replace this with the path to your image\n",
        "    image = Image.open('test.png')\n",
        "    #resize the image to a 224x224 with the same strategy as in TM2:\n",
        "    #resizing the image to be at least 224x224 and then cropping from the center\n",
        "    size = (224, 224)\n",
        "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "    #turn the image into a numpy array\n",
        "    image_array = np.asarray(image)\n",
        "    # Normalize the image\n",
        "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "    # Load the image into the array\n",
        "    data[0] = normalized_image_array\n",
        "\n",
        "    # run the inference\n",
        "    prediction = model.predict(data)\n",
        "\n",
        "    #get the 1D array\n",
        "    output = prediction[0]\n",
        "    #assign default value for max confidence\n",
        "    max_index = 0\n",
        "    max_confidence = output[0]\n",
        "    #find the maximum confidence and its index\n",
        "    for i in range(1, len(output)):\n",
        "        if max_confidence < output[i]:\n",
        "            max_confidence = output[i]\n",
        "            max_index = i\n",
        "    print(max_index, max_confidence)\n",
        "\n",
        "    file = open(\"labels.txt\",encoding=\"utf8\")\n",
        "    data = file.read().split(\"\\n\")\n",
        "    print(\"AI Result: \", data[max_index])\n",
        "    return data[max_index]    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'Adafruit_IO'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ACER\\Dropbox\\My PC (LAPTOP-S0HFNVES)\\Downloads\\converted_keras\\image_classifi.ipynb Cell 2\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ACER/Dropbox/My%20PC%20%28LAPTOP-S0HFNVES%29/Downloads/converted_keras/image_classifi.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mAdafruit_IO\u001b[39;00m \u001b[39mimport\u001b[39;00m MQTTClient\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Adafruit_IO'"
          ]
        }
      ],
      "source": [
        "from Adafruit_IO import MQTTClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1 0.9927012\n",
            "AI Result:  1 Class 2\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1 0.94582695\n",
            "AI Result:  1 Class 2\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1 0.9328242\n",
            "AI Result:  1 Class 2\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1 0.99752516\n",
            "AI Result:  1 Class 2\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1 0.9943242\n",
            "AI Result:  1 Class 2\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1 0.87626284\n",
            "AI Result:  1 Class 2\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1 0.92171323\n",
            "AI Result:  1 Class 2\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    time.sleep(5)\n",
        "    image_capture()\n",
        "    image_detector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "c42d99d755d00efaf066b964ceed011a4027ae5af520c8ef8190b9acee3a6094"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
